import os
import numpy as np
import torch
import torchvision.transforms as transforms
from flask import Flask, render_template, request, jsonify, send_file
from PIL import Image
import io
import base64
import faiss
import time
import pandas as pd


def load_coordinates_table(csv_path=None):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∞–±–ª–∏—Ü—ã —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∏–∑ XLSX —Ñ–∞–π–ª–∞"""
    global coordinates_df

    try:
        # –ò—â–µ–º XLSX —Ñ–∞–π–ª
        xlsx_files = [
            "coordinates.xlsx",
            "files/coordinates.xlsx",
            "data.xlsx",
            "files/data.xlsx"
        ]

        xlsx_path = None
        for path in xlsx_files:
            if os.path.exists(path):
                xlsx_path = path
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: {path}")
                break

        if xlsx_path is None:
            print("‚ùå –§–∞–π–ª —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            coordinates_df = None
            return None

        # –ó–∞–≥—Ä—É–∂–∞–µ–º XLSX —Ñ–∞–π–ª
        coordinates_df = pd.read_excel(xlsx_path)
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {len(coordinates_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(coordinates_df.columns)}")

        return coordinates_df

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ XLSX: {e}")
        coordinates_df = None
        return None


def get_coordinates_by_filename(filename):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã"""
    global coordinates_df

    if coordinates_df is None:
        return None, None

    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ –ø—É—Ç–∏
        basename = os.path.basename(filename)

        # –ò—â–µ–º –≤ –∫–æ–ª–æ–Ω–∫–µ "–ò–º—è —Ñ–∞–π–ª–∞"
        if '–ò–º—è —Ñ–∞–π–ª–∞' in coordinates_df.columns:
            # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            match = coordinates_df[coordinates_df['–ò–º—è —Ñ–∞–π–ª–∞'] == basename]

            if not match.empty:
                row = match.iloc[0]

                # –ë–µ—Ä–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                lon = row.get('longitude')
                lat = row.get('latitude')

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –ø—É—Å—Ç—ã–µ
                if pd.notna(lon) and pd.notna(lat):
                    return float(lon), float(lat)

        return None, None

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è {filename}: {e}")
        return None, None


# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
coordinates_df = None


# –ö–ª–∞—Å—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
class OptimizedResNetEmbeddingExtractor(torch.nn.Module):
    def __init__(self, embedding_dim=512):
        super(OptimizedResNetEmbeddingExtractor, self).__init__()
        self.backbone = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights='IMAGENET1K_V1')
        self.feature_extractor = torch.nn.Sequential(*list(self.backbone.children())[:-2])
        self.global_pool = torch.nn.AdaptiveAvgPool2d((1, 1))
        self.projection = torch.nn.Linear(2048, embedding_dim)

    def forward(self, x):
        features = self.feature_extractor(x)
        pooled = self.global_pool(features)
        flattened = pooled.view(pooled.size(0), -1)
        embeddings = self.projection(flattened)
        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
        return embeddings


# –ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å FAISS HNSW
class FAISSHNSWSearch:
    def __init__(self, dimension, max_elements=100000):
        self.dimension = dimension
        self.max_elements = max_elements
        self.index = None
        self.embeddings = None
        self.filenames = []

    def create_index(self, M=16, efConstruction=200, efSearch=50):
        """–°–æ–∑–¥–∞–Ω–∏–µ HNSW –∏–Ω–¥–µ–∫—Å–∞ –≤ FAISS"""
        self.index = faiss.IndexHNSWFlat(self.dimension, M)
        self.index.hnsw.efConstruction = efConstruction
        self.index.efSearch = efSearch
        print(f"–°–æ–∑–¥–∞–Ω FAISS HNSW –∏–Ω–¥–µ–∫—Å —Å M={M}, efConstruction={efConstruction}")

    def add_data(self, data, filenames=None):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∏–Ω–¥–µ–∫—Å"""
        if self.index is None:
            self.create_index()

        if data.shape[1] != self.dimension:
            raise ValueError(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö {data.shape[1]} –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é –∏–Ω–¥–µ–∫—Å–∞ {self.dimension}")

        self.index.add(data.astype('float32'))
        self.embeddings = data.astype('float32')
        if filenames is not None:
            self.filenames = filenames

        print(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(data)} –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å")

    def search(self, query, k=5, efSearch=None):
        """–ü–æ–∏—Å–∫ k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π"""
        if self.index is None:
            raise ValueError("–ò–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω!")

        if self.index.ntotal == 0:
            raise ValueError("–ò–Ω–¥–µ–∫—Å –ø—É—Å—Ç!")

        if efSearch is not None:
            self.index.efSearch = efSearch

        if isinstance(query, np.ndarray):
            if query.dtype != np.float32:
                query = query.astype('float32')
            if len(query.shape) == 1:
                query = query.reshape(1, -1)
        else:
            query = np.array(query, dtype='float32').reshape(1, -1)

        start_time = time.time()
        distances, labels = self.index.search(query, k)
        search_time = (time.time() - start_time) * 1000

        return labels[0], distances[0], search_time

    def get_index_stats(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–Ω–¥–µ–∫—Å–∞"""
        if self.index is None:
            return "–ò–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω"

        # –ë–ï–ó–û–ü–ê–°–ù–´–ô –î–û–°–¢–£–ü –ö –ü–ê–†–ê–ú–ï–¢–†–ê–ú
        stats = {
            'total_vectors': self.index.ntotal,
            'dimension': self.index.d,
            'efSearch': getattr(self.index, 'efSearch', 'N/A'),
        }

        # –ü–†–ê–í–ò–õ–¨–ù–´–ô –î–û–°–¢–£–ü –ö HNSW –ü–ê–†–ê–ú–ï–¢–†–ê–ú
        if hasattr(self.index, 'hnsw'):
            hnsw_obj = self.index.hnsw
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º getattr –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
            stats['M'] = getattr(hnsw_obj, 'M', getattr(hnsw_obj, 'efConstruction', 'N/A'))
            stats['efConstruction'] = getattr(hnsw_obj, 'efConstruction', 'N/A')
            stats['max_level'] = getattr(hnsw_obj, 'max_level', 'N/A')
            stats['entry_point'] = getattr(hnsw_obj, 'entry_point', 'N/A')
        else:
            stats['M'] = 'N/A'
            stats['efConstruction'] = 'N/A'
            stats['max_level'] = 'N/A'
            stats['entry_point'] = 'N/A'

        return stats

    def save_index(self, filename):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –¥–∏—Å–∫"""
        if self.index is None:
            raise ValueError("–ò–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω!")

        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É files –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs('files', exist_ok=True)
        filepath = os.path.join('files', filename + '.bin')

        faiss.write_index(self.index, filepath)
        metadata = {
            'filenames': self.filenames,
            'embeddings_shape': self.embeddings.shape if self.embeddings is not None else None
        }

        metadata_path = os.path.join('files', filename + '_metadata.npy')
        np.save(metadata_path, metadata)
        print(f"–ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filepath}")

    def load_index(self, filename):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ —Å –¥–∏—Å–∫–∞"""
        filepath = os.path.join('files', filename + '.bin')
        self.index = faiss.read_index(filepath)

        try:
            metadata_path = os.path.join('files', filename + '_metadata.npy')
            metadata = np.load(metadata_path, allow_pickle=True).item()
            self.filenames = metadata.get('filenames', [])
        except FileNotFoundError:
            print("–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∑–∞–≥—Ä—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å")

        print(f"–ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {filepath}")
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {self.index.ntotal} –≤–µ–∫—Ç–æ—Ä–æ–≤")


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'files/uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs('files', exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
model = None
faiss_searcher = None
filenames = []


def initialize_system(embeddings_path=None):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞"""
    global model, faiss_searcher, filenames, coordinates_df

    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ CPU
    device = torch.device('cpu')
    model = OptimizedResNetEmbeddingExtractor(embedding_dim=512)
    model = model.to(device)
    model.eval()
    print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")

    # –ó–ê–ì–†–£–ó–ö–ê –¢–ê–ë–õ–ò–¶–´ –ö–û–û–†–î–ò–ù–ê–¢
    coordinates_df = load_coordinates_table()

    # –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    try:
        if embeddings_path is None:
            # –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏
            possible_paths = [
                "files/embeddings.npy",
                "embeddings.npy",
                "files/moscow_embeddings_512.npy",
                "moscow_embeddings.npy"
            ]

            embeddings_path = None
            for path in possible_paths:
                if os.path.exists(path):
                    embeddings_path = path
                    print(f"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {path}")
                    break

        if embeddings_path is None:
            print("–§–∞–π–ª —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å–∫ –≤ –¥–µ–º–æ-—Ä–µ–∂–∏–º–µ.")
            # –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–∏–Ω–¥–µ–∫—Å —Å —Å–ª—É—á–∞–π–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            faiss_searcher = FAISSHNSWSearch(dimension=512, max_elements=1000)
            demo_embeddings = np.random.rand(50, 512).astype('float32')
            demo_filenames = [f"files/demo_{i}.jpg" for i in range(50)]
            faiss_searcher.add_data(demo_embeddings, demo_filenames)
            filenames = demo_filenames
            print("‚úÖ –î–µ–º–æ-—Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return

        print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑: {embeddings_path}")
        data = np.load(embeddings_path, allow_pickle=True).item()

        embeddings = data['embeddings']
        filenames = data['filenames']

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FAISS HNSW –∏–Ω–¥–µ–∫—Å–∞
        print("–°–æ–∑–¥–∞–Ω–∏–µ FAISS HNSW –∏–Ω–¥–µ–∫—Å–∞...")
        faiss_searcher = FAISSHNSWSearch(dimension=512, max_elements=len(embeddings))
        faiss_searcher.add_data(embeddings, filenames)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å –≤ –ø–∞–ø–∫—É files
        faiss_searcher.save_index("search_index")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = faiss_searcher.get_index_stats()
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞: {stats}")

        print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(filenames)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω–¥–µ–∫—Å–∞: {e}")
        # –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-—Ä–µ–∂–∏–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
        faiss_searcher = FAISSHNSWSearch(dimension=512, max_elements=1000)
        demo_embeddings = np.random.rand(20, 512).astype('float32')
        demo_filenames = [f"files/demo_{i}.jpg" for i in range(20)]
        faiss_searcher.add_data(demo_embeddings, demo_filenames)
        filenames = demo_filenames
        print("‚úÖ –î–µ–º–æ-—Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (—Ä–µ–∂–∏–º –æ—à–∏–±–∫–∏)")


def preprocess_image(image):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏"""
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    if isinstance(image, str):
        image = Image.open(image).convert('RGB')
    elif isinstance(image, bytes):
        image = Image.open(io.BytesIO(image)).convert('RGB')

    return transform(image).unsqueeze(0)


def get_image_base64(image_path):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64 –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ HTML"""
    try:
        # –ï—Å–ª–∏ –ø—É—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if os.path.exists(image_path):
            with open(image_path, 'rb') as img_file:
                image_data = img_file.read()
                return base64.b64encode(image_data).decode('utf-8')

        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        filename_only = os.path.basename(image_path)

        # –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞
        search_paths = [
            os.path.join('files', filename_only),
            os.path.join('dataset/–û–±—ä–µ–∫—Ç—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –≥—Ä–∞–¥–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º –Ω–æ—Ä–º–∞–º_00-022_–ê–≤–≥—É—Å—Ç', filename_only),
            filename_only,
            os.path.join('files', 'uploads', filename_only)
        ]

        for path in search_paths:
            if os.path.exists(path):
                with open(path, 'rb') as img_file:
                    image_data = img_file.read()
                    return base64.b64encode(image_data).decode('utf-8')

        print(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        return ""

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
        return ""


# –ú–∞—Ä—à—Ä—É—Ç—ã Flask
@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
    stats = faiss_searcher.get_index_stats() if faiss_searcher else {}
    total_images = stats.get('total_vectors', 0) if isinstance(stats, dict) else 0

    return render_template('index.html',
                           total_images=total_images,
                           model_ready=model is not None,
                           index_stats=stats)


@app.route('/search')
def search_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–∏—Å–∫–∞"""
    return render_template('search.html')


@app.route('/api/search', methods=['POST'])
def api_search():
    """API endpoint –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    if model is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞'}), 500

    if faiss_searcher is None or faiss_searcher.index.ntotal == 0:
        return jsonify({'error': '–ü–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω'}), 500

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω –ª–∏ —Ñ–∞–π–ª
        if 'image' not in request.files:
            return jsonify({'error': '–§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ'}), 400

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
        if not file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'}), 400

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
        temp_path = os.path.join(app.config['UPLOAD_FOLDER'], 'temp_search_image.jpg')
        file.save(temp_path)

        # –ß–∏—Ç–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        with open(temp_path, 'rb') as f:
            image_bytes = f.read()

        input_tensor = preprocess_image(image_bytes)

        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
        with torch.no_grad():
            device = next(model.parameters()).device
            input_tensor = input_tensor.to(device)
            query_embedding = model(input_tensor).cpu().numpy()

        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        k = min(int(request.form.get('k', 5)), 20)
        labels, distances, search_time = faiss_searcher.search(query_embedding, k=k)

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = []
        for i, (label, distance) in enumerate(zip(labels, distances)):
            if 0 <= label < len(faiss_searcher.filenames):
                image_path = faiss_searcher.filenames[label]
                image_base64 = get_image_base64(image_path)

                # –ü–û–õ–£–ß–ê–ï–ú –ö–û–û–†–î–ò–ù–ê–¢–´
                longitude, latitude = get_coordinates_by_filename(image_path)

                results.append({
                    'rank': i + 1,
                    'filename': os.path.basename(image_path),
                    'filepath': image_path,
                    'distance': float(distance),
                    'image_base64': image_base64,
                    'label_index': int(label),
                    'longitude': longitude,
                    'latitude': latitude,
                    'has_coordinates': longitude is not None and latitude is not None
                })

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª

        try:

            os.remove(temp_path)

        except:

            pass

        return jsonify({

            'success': True,

            'results': results,

            'search_time_ms': search_time,

            'total_found': len(results),

            'query_dimension': query_embedding.shape[1]

        })


    except Exception as e:

        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")

        return jsonify({'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}'}), 500


@app.route('/api/system_info')
def system_info():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ"""
    stats = faiss_searcher.get_index_stats() if faiss_searcher else {}

    info = {
        'model_loaded': model is not None,
        'index_loaded': faiss_searcher is not None and faiss_searcher.index.ntotal > 0,
        'total_images': stats.get('total_vectors', 0) if isinstance(stats, dict) else 0,
        'embedding_dimension': stats.get('dimension', 0) if isinstance(stats, dict) else 0,
        'index_type': 'FAISS HNSW',
        'device': 'CPU'
    }

    return jsonify(info)


@app.route('/api/image/<filename>')
def serve_image(filename):
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –æ—Ç–¥–∞—á–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    try:
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏
        safe_filename = os.path.basename(filename)

        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏
        possible_paths = [
            os.path.join('files', safe_filename),
            safe_filename,
            os.path.join('dataset/–û–±—ä–µ–∫—Ç—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –≥—Ä–∞–¥–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º –Ω–æ—Ä–º–∞–º_00-022_–ê–≤–≥—É—Å—Ç', safe_filename)
        ]

        for path in possible_paths:
            if os.path.exists(path):
                return send_file(path)

        return "Image not found", 404
    except Exception as e:
        return f"Error serving image: {str(e)}", 500


@app.route('/api/upload_index', methods=['POST'])
def upload_index():
    """API –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400

        if not file.filename.endswith('.npy'):
            return jsonify({'error': '–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ .npy'}), 400

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É files
        filepath = os.path.join('files', 'embeddings.npy')
        file.save(filepath)

        # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É
        initialize_system(filepath)

        return jsonify({
            'success': True,
            'message': '–§–∞–π–ª —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ —Å–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞'
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload_coordinates', methods=['POST'])
def upload_coordinates():
    """API –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ CSV —Ñ–∞–π–ª–∞ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏"""
    global coordinates_df

    try:
        if 'file' not in request.files:
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400

        if not file.filename.endswith('.csv'):
            return jsonify({'error': '–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ .csv'}), 400

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É files
        filepath = os.path.join('files', 'coordinates.csv')
        file.save(filepath)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
        coordinates_df = load_coordinates_table(filepath)

        return jsonify({
            'success': True,
            'message': f'–¢–∞–±–ª–∏—Ü–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ó–∞–ø–∏—Å–µ–π: {len(coordinates_df) if coordinates_df is not None else 0}',
            'columns': list(coordinates_df.columns) if coordinates_df is not None else []
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ—à–∏–±–æ–∫
@app.errorhandler(413)
def too_large(e):
    return jsonify({'error': '–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π'}), 413


@app.errorhandler(404)
def not_found(e):
    return jsonify({'error': '–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404


@app.errorhandler(500)
def internal_error(e):
    return jsonify({'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'}), 500


if __name__ == '__main__':
    # –î–ª—è Windows
    import multiprocessing

    multiprocessing.freeze_support()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    initialize_system()

    # –ó–∞–ø—É—Å–∫–∞–µ–º Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    port = 5000
    debug = True

    print(f"üìç –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ http://localhost:{port}")
    print(f"üìÅ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫—É 'files'")
    print("üìñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã:")
    print("   - GET  / (–≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞)")
    print("   - GET  /search (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–∏—Å–∫–∞)")
    print("   - POST /api/search (–ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
    print("   - GET  /api/system_info (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ)")
    print("   - POST /api/upload_index (–∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)")

    app.run(host='0.0.0.0', port=port, use_reloader=False)